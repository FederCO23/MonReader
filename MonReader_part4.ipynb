{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b22c4196",
   "metadata": {},
   "source": [
    "## MonReader - part 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2956a14e",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716b8abb",
   "metadata": {},
   "source": [
    "### Text-to-Speech Generation from OCR Transcriptions (Audiobook-Style Rendering)\n",
    "\n",
    "**Objective.**  \n",
    "Transform the page-level OCR transcriptions produced in **MonReader – Part 3** into **spoken audio**, enabling end-to-end document accessibility and audiobook-style consumption.  \n",
    "This part evaluates modern **Text-to-Speech (TTS)** models on long-form literary text, focusing on intelligibility, prosody, multilingual robustness, and generation efficiency.\n",
    "\n",
    "We use the same two sources as previous parts:\n",
    "- *The Chamber* — John Grisham *(English)*\n",
    "- *A onda que se ergueu no mar* — Ruy Castro *(Portuguese)*\n",
    "\n",
    "All text input is sourced from the verified per-page `.txt` outputs generated by the best-performing OCR model (**Qwen2.5-VL**), ensuring a clean and stable foundation for speech synthesis.\n",
    "\n",
    "**Why this experiment.**  \n",
    "While OCR converts visual documents into text, **Text-to-Speech closes the accessibility loop**, enabling hands-free reading, audio archiving, and downstream multimodal applications helping the blind, the researchers and for everyone else in need for fully automatic, highly fast and high-quality document scanning in bulk.\n",
    "\n",
    "Long-form literary TTS presents challenges beyond short prompts: paragraph continuity, punctuation-aware prosody, proper-noun pronunciation, multilingual phonemes, and stability over extended generation windows. This experiment measures how well current TTS systems handle these constraints in a realistic, book-scale setting.\n",
    "\n",
    "**Proposed Pipeline Overview**\n",
    "\n",
    "1. **I – Data Preparation**  \n",
    "   Normalize and structure OCR text for speech synthesis: page ordering, light TTS-oriented text normalization (hyphen joins, punctuation handling), language tagging, and chunking to respect model limits.\n",
    "\n",
    "2. **J – TTS Model Benchmarking**  \n",
    "   Evaluate three leading Text-to-Speech models on representative excerpts from both books.  \n",
    "   Comparison dimensions include generation speed, pronunciation accuracy, prosody, multilingual handling (English vs. Portuguese), and long-form stability.\n",
    "\n",
    "3. **K – Full Audio Generation**  \n",
    "   Using the selected TTS model and fixed configuration, generate per-page audio files for both books.  \n",
    "   Outputs include structured audio manifests and reproducible file layouts suitable for later merging into chapter- or book-level recordings.\n",
    "\n",
    "> This part prioritizes **reproducibility and minimal intervention**: the OCR pipeline remains unchanged, and only lightweight, TTS-specific normalization is applied to the extracted text.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e935cd",
   "metadata": {},
   "source": [
    "----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b387d87",
   "metadata": {},
   "source": [
    "#### Imports and Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3dad98f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "import json\n",
    "import time\n",
    "import math\n",
    "import unicodedata\n",
    "import pandas as pd\n",
    "from typing import List, Dict, Iterable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77db430b",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE = Path.cwd()\n",
    "WORK_DIR = BASE / \"work\"\n",
    "\n",
    "# OCR outputs from Part 3\n",
    "STEPH_DIR = WORK_DIR / \"stepH_qwen2p5vl_full\"\n",
    "\n",
    "# Part 4 outputs\n",
    "STEP4_DIR = WORK_DIR / \"step4_tts\"\n",
    "STEP4_DIR.mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588a5ee4",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4ec0ef",
   "metadata": {},
   "source": [
    "### Step I — Data Preparation for Text-to-Speech\n",
    "\n",
    "**Goal.**  \n",
    "Transform OCR-derived page outputs into **clean, continuous, speech-ready text** while preserving semantic content and correct reading order.\n",
    "\n",
    "This step performs **strictly minimal, TTS-oriented processing**, with no OCR correction or semantic rewriting. The focus is on structural consistency and speech robustness.\n",
    "\n",
    "**Processing stages in this step:**\n",
    "1- inspection of per-page OCR JSON structure\n",
    "2- explicit verification of page ordering\n",
    "3- extraction and concatenation of page-level text\n",
    "- removal of OCR and formatting artifacts\n",
    "- repair of hyphenated and line-wrapped words\n",
    "- generation of canonical continuous prose\n",
    "- sentence-aware chunking to respect TTS model limits\n",
    "\n",
    "No linguistic enhancement, paraphrasing, or content modification is applied. The output of this step serves as the **single source of truth** for all subsequent Text-to-Speech benchmarking and audio generation.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e581f814",
   "metadata": {},
   "source": [
    "#### Step I.1 - Inspection of per-page OCR JSON structure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a9acd7",
   "metadata": {},
   "source": [
    "Each page has one JSON like:\n",
    "\n",
    "```pgsql\n",
    "work/\n",
    "└─ stepH_qwen2p5vl_full/\n",
    "   └─ <BOOK_ID>/\n",
    "      └─ json/\n",
    "         └─ pagXX.json\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "73c1935a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9b2c4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'image': 'pag12.JPEG',\n",
      " 'image_path': 'e:\\\\Devs\\\\pyEnv-1\\\\Apziva\\\\MonReader\\\\data\\\\books\\\\A_onda_que_se_ergueu_no_mar-Ruy_Castro\\\\images\\\\pag12.JPEG',\n",
      " 'latency_s': 870.2552971839905,\n",
      " 'model': 'qwen2.5vl:latest',\n",
      " 'options': {'num_predict': 1536,\n",
      "             'repeat_penalty': 1.25,\n",
      "             'stop': ['}\\n', '}\\r\\n', '}'],\n",
      "             'temperature': 0,\n",
      "             'top_p': 1},\n",
      " 'parsed': {'degenerate': False,\n",
      "            'json_objs': 0,\n",
      "            'language': 'guess',\n",
      "            'lines': ['{',\n",
      "                      '  \"language\": \"por\",',\n",
      "                      '  \"lines\": [',\n",
      "                      '    \"A trilha\",',\n",
      "                      '    \"sonora de um\",',\n",
      "                      '    \"país ideal\",',\n",
      "                      '    \"\",',\n",
      "                      '    \"Olha que coisa mais linda: as garotas de '\n",
      "                      'Ipanema-1961\",',\n",
      "                      '    \"tomavam cuba-libre, dirigiam Kharman-Ghias e '\n",
      "                      'voavam\",',\n",
      "                      '    \"pela Panair. Usavam frasqueira, vestido-tubinho, '\n",
      "                      'cílio\",',\n",
      "                      '    \"postiço, peruca, laquê. Diziam-se '\n",
      "                      'existencialistas, adoravam\",',\n",
      "                      '    \"arte abstrata e não perdiam um filme da Nouvelle '\n",
      "                      'Vague. Seus\",',\n",
      "                      '    \"points eram o Beco das Garrafas, a Cinemateca, o '\n",
      "                      'Arpoador. Iam\",',\n",
      "                      '    \"à praia com a camisa social do irmão e, sob esta, '\n",
      "                      'um biquíni que\",',\n",
      "                      '    \"de tão insolente, fazia o sangue dos rapazes '\n",
      "                      'ferver da maneira\",',\n",
      "                      '    \"mais inconveniente.\",',\n",
      "                      '    \"Tudo isso passou. A querida Panair nunca mais '\n",
      "                      'voou, a\",',\n",
      "                      '    \"Nouvelle Vague é um filme em preto e branco e '\n",
      "                      'ninguém mais\",',\n",
      "                      '    \"toma cuba-libre — quem pensaria hoje em misturar '\n",
      "                      'rum com\",',\n",
      "                      '    \"Coca-Cola? Quanto àquele biquíni, era mesmo '\n",
      "                      'insolente, embora\",',\n",
      "                      '    \"por padrões subsequentes, sua calcinha contivesse '\n",
      "                      'pano\",',\n",
      "                      '    \"para fabricar dois ou três pára-quedas. Dito '\n",
      "                      'assim, é como se, em\",',\n",
      "                      '    \"1961, o céu do Brasil ainda fosse povoado por '\n",
      "                      'pterodáctilos.\",',\n",
      "                      '    \"Mas há uma exceção. A música que aquelas garotas '\n",
      "                      'escutavam\",',\n",
      "                      '    \"na época continua a ser ouvida — um milênio depois '\n",
      "                      '—\",',\n",
      "                      '    \"como se brotasse das esferas: a Bossa Nova.\",',\n",
      "                      '    \"Acredite ou não, em números absolutos ouve-se mais '\n",
      "                      'Bossa\",',\n",
      "                      '    \"Nova hoje do que em 1961. E ela não brota das '\n",
      "                      'esferas, mas\",',\n",
      "                      '    \"é produzida ao vivo, pelos gogós, dedos e pulmões '\n",
      "                      'de artistas\",',\n",
      "                      '    \"de todas as idades, em lugares fechados ou ao ar '\n",
      "                      'livre, em quatro\",',\n",
      "                      '    \"ou cinco continentes. Ouviu-se Bossa Nova em salas '\n",
      "                      'de concerto\",',\n",
      "                      '    \"teatros, boates, bares, clubes, escolas, estádios, '\n",
      "                      'praças, praias\",',\n",
      "                      '    \"e quiosques e, ultimamente, como uma epidemia, nas '\n",
      "                      'ruas noturnas\"',\n",
      "                      '  ]'],\n",
      "            'parse_error': 'JSONDecodeError(\"Expecting \\',\\' delimiter: line '\n",
      "                           '35 column 1 (char 1785)\")',\n",
      "            'parsed_json': False},\n",
      " 'prompt': 'You are an OCR transcriber.\\n'\n",
      "           '\\n'\n",
      "           'Return ONLY one valid JSON object with keys:\\n'\n",
      "           '- \"language\": one of [\"eng\",\"por\",\"guess\"]\\n'\n",
      "           '- \"lines\": an array of strings, one per line in reading order\\n'\n",
      "           '\\n'\n",
      "           'Rules:\\n'\n",
      "           '- Do NOT repeat the JSON object.\\n'\n",
      "           '- Do NOT include any text outside the single JSON object.\\n'\n",
      "           '- Preserve line breaks and punctuation exactly as seen.\\n'\n",
      "           '- If unsure about a character, copy it as best you can (do not '\n",
      "           'explain).\\n'\n",
      "           '\\n'\n",
      "           'Transcribe the image verbatim.',\n",
      " 'raw_response': '{\\n'\n",
      "                 '  \"language\": \"por\",\\n'\n",
      "                 '  \"lines\": [\\n'\n",
      "                 '    \"A trilha\",\\n'\n",
      "                 '    \"sonora de um\",\\n'\n",
      "                 '    \"país ideal\",\\n'\n",
      "                 '    \"\",\\n'\n",
      "                 '    \"Olha que coisa mais linda: as garotas de '\n",
      "                 'Ipanema-1961\",\\n'\n",
      "                 '    \"tomavam cuba-libre, dirigiam Kharman-Ghias e voavam\",\\n'\n",
      "                 '    \"pela Panair. Usavam frasqueira, vestido-tubinho, '\n",
      "                 'cílio\",\\n'\n",
      "                 '    \"postiço, peruca, laquê. Diziam-se existencialistas, '\n",
      "                 'adoravam\",\\n'\n",
      "                 '    \"arte abstrata e não perdiam um filme da Nouvelle Vague. '\n",
      "                 'Seus\",\\n'\n",
      "                 '    \"points eram o Beco das Garrafas, a Cinemateca, o '\n",
      "                 'Arpoador. Iam\",\\n'\n",
      "                 '    \"à praia com a camisa social do irmão e, sob esta, um '\n",
      "                 'biquíni que\",\\n'\n",
      "                 '    \"de tão insolente, fazia o sangue dos rapazes ferver da '\n",
      "                 'maneira\",\\n'\n",
      "                 '    \"mais inconveniente.\",\\n'\n",
      "                 '    \"Tudo isso passou. A querida Panair nunca mais voou, '\n",
      "                 'a\",\\n'\n",
      "                 '    \"Nouvelle Vague é um filme em preto e branco e ninguém '\n",
      "                 'mais\",\\n'\n",
      "                 '    \"toma cuba-libre — quem pensaria hoje em misturar rum '\n",
      "                 'com\",\\n'\n",
      "                 '    \"Coca-Cola? Quanto àquele biquíni, era mesmo insolente, '\n",
      "                 'embora\",\\n'\n",
      "                 '    \"por padrões subsequentes, sua calcinha contivesse '\n",
      "                 'pano\",\\n'\n",
      "                 '    \"para fabricar dois ou três pára-quedas. Dito assim, é '\n",
      "                 'como se, em\",\\n'\n",
      "                 '    \"1961, o céu do Brasil ainda fosse povoado por '\n",
      "                 'pterodáctilos.\",\\n'\n",
      "                 '    \"Mas há uma exceção. A música que aquelas garotas '\n",
      "                 'escutavam\",\\n'\n",
      "                 '    \"na época continua a ser ouvida — um milênio depois —\",\\n'\n",
      "                 '    \"como se brotasse das esferas: a Bossa Nova.\",\\n'\n",
      "                 '    \"Acredite ou não, em números absolutos ouve-se mais '\n",
      "                 'Bossa\",\\n'\n",
      "                 '    \"Nova hoje do que em 1961. E ela não brota das esferas, '\n",
      "                 'mas\",\\n'\n",
      "                 '    \"é produzida ao vivo, pelos gogós, dedos e pulmões de '\n",
      "                 'artistas\",\\n'\n",
      "                 '    \"de todas as idades, em lugares fechados ou ao ar livre, '\n",
      "                 'em quatro\",\\n'\n",
      "                 '    \"ou cinco continentes. Ouviu-se Bossa Nova em salas de '\n",
      "                 'concerto\",\\n'\n",
      "                 '    \"teatros, boates, bares, clubes, escolas, estádios, '\n",
      "                 'praças, praias\",\\n'\n",
      "                 '    \"e quiosques e, ultimamente, como uma epidemia, nas ruas '\n",
      "                 'noturnas\"\\n'\n",
      "                 '  ]\\n',\n",
      " 'status': 200,\n",
      " 'timestamp_utc': '2026-01-02T19:09:44Z'}\n"
     ]
    }
   ],
   "source": [
    "# print the JSON structure of the page12 from the first book\n",
    "BOOK_ID = \"A_onda_que_se_ergueu_no_mar-Ruy_Castro\"\n",
    "PAGE = \"pag12\"\n",
    "\n",
    "json_path = Path(\"work/stepH_qwen2p5vl_full\") / BOOK_ID / \"json\" / f\"{PAGE}.json\"\n",
    "\n",
    "with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "pprint(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af94085",
   "metadata": {},
   "source": [
    "#### Step I.2 - Explicit verification of page ordering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116e490e",
   "metadata": {},
   "source": [
    "Page filenames like \"pag2.JPEG\" vs \"pag10.JPEG\" will sort incorrectly with plain string sorting.\n",
    "We define an explicit \"natural sort\" that extracts the numeric page id and sorts by it, the functions were included in the `MonReader_tools.py` library.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7dfc6e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import MonReader_tools\n",
    "\n",
    "importlib.reload(MonReader_tools)\n",
    "\n",
    "from MonReader_tools import (\n",
    "    page_number_from_name, list_pages_sorted, verify_page_order\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "95f921bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> The_Chamber-John_Grisham (json)\n",
      "Directory: e:\\Devs\\pyEnv-1\\Apziva\\MonReader\\work\\stepH_qwen2p5vl_full\\The_Chamber-John_Grisham\\json\n",
      "Order preview:\n",
      " - pag0.json\n",
      " - pag2.json\n",
      " - pag4.json\n",
      " - pag6.json\n",
      " - pag8.json\n",
      " - pag10.json\n",
      " - pag12.json\n",
      " - pag14.json\n",
      " - pag16.json\n",
      " - pag18.json\n",
      " - pag20.json\n",
      " - pag22.json\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>page_n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pag0.json</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pag2.json</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pag4.json</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pag6.json</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pag8.json</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>pag10.json</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>pag12.json</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>pag14.json</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>pag16.json</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>pag18.json</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>pag20.json</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>pag22.json</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          name  page_n\n",
       "0    pag0.json       0\n",
       "1    pag2.json       2\n",
       "2    pag4.json       4\n",
       "3    pag6.json       6\n",
       "4    pag8.json       8\n",
       "5   pag10.json      10\n",
       "6   pag12.json      12\n",
       "7   pag14.json      14\n",
       "8   pag16.json      16\n",
       "9   pag18.json      18\n",
       "10  pag20.json      20\n",
       "11  pag22.json      22"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> A_onda_que_se_ergueu_no_mar-Ruy_Castro (json)\n",
      "Directory: e:\\Devs\\pyEnv-1\\Apziva\\MonReader\\work\\stepH_qwen2p5vl_full\\A_onda_que_se_ergueu_no_mar-Ruy_Castro\\json\n",
      "Order preview:\n",
      " - pag12.json\n",
      " - pag16.json\n",
      " - pag18.json\n",
      " - pag20.json\n",
      " - pag22.json\n",
      " - pag24.json\n",
      " - pag26.json\n",
      " - pag28.json\n",
      " - pag32.json\n",
      " - pag36.json\n",
      " - pag40.json\n",
      " - pag44.json\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>page_n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pag12.json</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pag16.json</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pag18.json</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pag20.json</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pag22.json</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>pag24.json</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>pag26.json</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>pag28.json</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>pag32.json</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>pag36.json</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>pag40.json</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>pag44.json</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          name  page_n\n",
       "0   pag12.json      12\n",
       "1   pag16.json      16\n",
       "2   pag18.json      18\n",
       "3   pag20.json      20\n",
       "4   pag22.json      22\n",
       "5   pag24.json      24\n",
       "6   pag26.json      26\n",
       "7   pag28.json      28\n",
       "8   pag32.json      32\n",
       "9   pag36.json      36\n",
       "10  pag40.json      40\n",
       "11  pag44.json      44"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run verification for both books (Step H JSON outputs)\n",
    "\n",
    "BOOKS = [\n",
    "    \"The_Chamber-John_Grisham\",\n",
    "    \"A_onda_que_se_ergueu_no_mar-Ruy_Castro\",\n",
    "]\n",
    "\n",
    "dfs = {}\n",
    "for b in BOOKS:\n",
    "    dfs[b] = verify_page_order(b, which=\"json\", preview=50)\n",
    "    display(dfs[b].head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2684541e",
   "metadata": {},
   "source": [
    "### Step I.3 - extraction and concatenation of page-level text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388c89cf",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MonReader_env_part3",
   "language": "python",
   "name": "monreader_env_part3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
